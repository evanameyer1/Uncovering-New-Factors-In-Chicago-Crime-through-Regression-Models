{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_pre_feature_selection = pd.read_csv('../../data/pre_training/area_pre_feature_selection.csv')\n",
    "district_pre_feature_selection = pd.read_csv('../../data/pre_training/district_pre_feature_selection.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_features = area_pre_feature_selection.drop('area_crimes_this_hour', axis=1)\n",
    "district_features = district_pre_feature_selection.drop('district_crimes_this_hour', axis=1)\n",
    "\n",
    "area_target = area_pre_feature_selection[['year', 'area_crimes_this_hour']]\n",
    "district_target = district_pre_feature_selection[['year', 'district_crimes_this_hour']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break the area dataset into testing and training datasets\n",
    "area_feature_training_data = area_features[area_features['year'] < 2020].reset_index(drop=True)\n",
    "area_feature_testing_data = area_features[area_features['year'] == 2020].reset_index(drop=True)\n",
    "\n",
    "area_target_training_data = area_target[area_target['year'] < 2020].reset_index(drop=True)\n",
    "area_target_testing_data = area_target[area_target['year'] == 2020].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break the district dataset into testing and training datasets\n",
    "district_feature_training_data = district_features[district_features['year'] < 2020].reset_index(drop=True)\n",
    "district_feature_testing_data = district_features[district_features['year'] == 2020].reset_index(drop=True)\n",
    "\n",
    "district_target_training_data = district_target[district_target['year'] < 2020].reset_index(drop=True)\n",
    "district_target_testing_data = district_target[district_target['year'] == 2020].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_target_training_data = area_target_training_data.drop('year', axis=1)\n",
    "area_target_testing_data = area_target_testing_data.drop('year', axis=1)\n",
    "district_target_training_data = district_target_training_data.drop('year', axis=1)\n",
    "district_target_testing_data = district_target_testing_data.drop('year', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Final Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_area_feature_training_data = area_feature_training_data.drop('date_hour', axis=1)\n",
    "lr_area_feature_testing_data = area_feature_testing_data.drop('date_hour', axis=1)\n",
    "\n",
    "lr_district_feature_training_data = district_feature_training_data.drop('date_hour', axis=1)\n",
    "lr_district_feature_testing_data = district_feature_testing_data.drop('date_hour', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target encoding of district/area columns\n",
    "area_means = area_pre_feature_selection.groupby('area_id')['area_crimes_this_hour'].mean()\n",
    "district_means = district_pre_feature_selection.groupby('district')['district_crimes_this_hour'].mean()\n",
    "\n",
    "lr_area_feature_training_data['area_id_target_encoded'] = lr_area_feature_training_data['area_id'].map(area_means)\n",
    "lr_area_feature_testing_data['area_id_target_encoded'] = lr_area_feature_testing_data['area_id'].map(area_means)\n",
    "\n",
    "lr_district_feature_training_data['district_target_encoded'] = lr_district_feature_training_data['district'].map(district_means)\n",
    "lr_district_feature_testing_data['district_target_encoded'] = lr_district_feature_testing_data['district'].map(district_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency encoding of district/area columns\n",
    "area_freq = area_pre_feature_selection['area_id'].value_counts() / len(area_pre_feature_selection)\n",
    "district_freq = district_pre_feature_selection['district'].value_counts() / len(district_pre_feature_selection)\n",
    "\n",
    "lr_area_feature_training_data['area_id_freq_encoded'] = lr_area_feature_training_data['area_id'].map(area_freq)\n",
    "lr_area_feature_testing_data['area_id_freq_encoded'] = lr_area_feature_testing_data['area_id'].map(area_freq)\n",
    "\n",
    "lr_district_feature_training_data['district_freq_encoded'] = lr_district_feature_training_data['district'].map(district_freq)\n",
    "lr_district_feature_testing_data['district_freq_encoded'] = lr_district_feature_testing_data['district'].map(district_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_area_feature_training_data.drop('area_id', axis=1, inplace=True)\n",
    "lr_area_feature_testing_data.drop('area_id', axis=1, inplace=True)\n",
    "\n",
    "lr_district_feature_training_data.drop('district', axis=1, inplace=True)\n",
    "lr_district_feature_testing_data.drop('district', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_datatypes(df):\n",
    "    float_cols = df.select_dtypes(include=['float64']).columns\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "\n",
    "    int_cols = df.select_dtypes(include=['int64']).columns\n",
    "    df[int_cols] = df[int_cols].astype(np.int32)    \n",
    "      \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_area_feature_training_data = patch_datatypes(lr_area_feature_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_area_feature_testing_data = patch_datatypes(lr_area_feature_testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_district_feature_training_data = patch_datatypes(lr_district_feature_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_district_feature_testing_data = patch_datatypes(lr_district_feature_testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_correlation_heatmap(df):\n",
    "    # Generate a mask to onlyshow the bottom triangle\n",
    "    mask = np.triu(np.ones_like(df.corr(), dtype=bool))\n",
    "\n",
    "    # generate heatmap\n",
    "    plt.figure(figsize=(70,70))\n",
    "    sns.heatmap(df.corr(), annot=True, mask=mask, vmin=-1, vmax=1)\n",
    "    plt.title('Correlation Coefficient Of Area Crime Predictors')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_correlation_heatmap(lr_area_feature_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_correlation_heatmap(lr_district_feature_training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using VIF to Remove Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute VIF for all features\n",
    "def compute_vif(feature_df):\n",
    "    print(f\"{datetime.now()} - Starting VIF computation\")\n",
    "    X = feature_df.copy()\n",
    "    # The calculation of variance inflation requires a constant\n",
    "    X['intercept'] = 1\n",
    "    \n",
    "    # Create dataframe to store VIF values\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"feature\"] = X.columns\n",
    "    vif[\"vif\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    vif = vif[vif['feature'] != 'intercept']\n",
    "    \n",
    "    print(f\"{datetime.now()} - Completed VIF computation\")\n",
    "    return vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to optimize VIF by dropping features with high VIF values\n",
    "def optimize_vif(feature_df, vif_threshold):\n",
    "    print(f\"{datetime.now()} - Starting VIF optimization\")\n",
    "    df = feature_df.copy()       \n",
    "\n",
    "    vif_df = compute_vif(feature_df)\n",
    "    \n",
    "    while (vif_df['vif'] >= vif_threshold).any():\n",
    "        print(f\"{datetime.now()} - Current VIF values:\\n{vif_df}\")\n",
    "        largest_vif_feature = vif_df.loc[vif_df['vif'].idxmax(), 'feature']\n",
    "        print(f\"{datetime.now()} - Dropping feature: {largest_vif_feature} with VIF score of: {vif_df['vif'].max()}\")\n",
    "        df = df.drop(columns=[largest_vif_feature])\n",
    "        vif_df = compute_vif(df)\n",
    "    \n",
    "    print(f\"{datetime.now()} - Completed VIF optimization\")\n",
    "    return vif_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_area_selected_features_ten = optimize_vif(lr_area_feature_training_data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_district_selected_features_ten = optimize_vif(lr_district_feature_training_data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_area_selected_features_five = optimize_vif(lr_area_feature_training_data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_district_selected_features_five = optimize_vif(lr_district_feature_training_data, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using SFS for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_model_ten = LinearRegression()\n",
    "area_sfs_ten = SFS(area_model_ten, k_features='best', forward=True, floating=False, scoring='neg_mean_squared_error', cv=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_sfs_ten.fit(lr_area_feature_training_data[[lr_area_selected_features_ten['features'].values]], area_target_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_model_five = LinearRegression()\n",
    "area_sfs_five = SFS(area_model_five, k_features='best', forward=True, floating=False, scoring='neg_mean_squared_error', cv=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_sfs_five.fit(lr_area_feature_training_data[[lr_area_selected_features_five['features'].values]], area_target_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_model_ten = LinearRegression()\n",
    "district_sfs_ten = SFS(district_model_ten, k_features='best', forward=True, floating=False, scoring='neg_mean_squared_error', cv=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_sfs_ten.fit(lr_district_feature_training_data[[lr_district_selected_features_ten['features'].values]], area_target_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_model_five = LinearRegression()\n",
    "district_sfs_five = SFS(district_model_five, k_features='best', forward=True, floating=False, scoring='neg_mean_squared_error', cv=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_sfs_five.fit(lr_district_feature_training_data[[lr_district_selected_features_five['features'].values]], area_target_training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the cross-validation scores from the SFS objects\n",
    "area_cv_scores_ten = area_sfs_ten.get_metric_dict()\n",
    "area_cv_scores_five = area_sfs_five.get_metric_dict()\n",
    "\n",
    "# Get the best scores (least negative mean squared error)\n",
    "area_best_score_ten = max(area_cv_scores_ten.values(), key=lambda x: x['avg_score'])\n",
    "area_best_score_five = max(area_cv_scores_five.values(), key=lambda x: x['avg_score'])\n",
    "\n",
    "# Define the final model based on the best score\n",
    "area_selected_features = area_sfs_ten.feature_names_ if area_best_score_ten > area_best_score_five else area_sfs_five.feature_names_\n",
    "lr_area_feature_training_data = lr_area_feature_training_data[[list(area_selected_features)]]\n",
    "lr_area_feature_testing_data = lr_area_feature_testing_data[[list(area_selected_features)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the cross-validation scores from the SFS objects\n",
    "district_cv_scores_ten = district_sfs_ten.get_metric_dict()\n",
    "district_cv_scores_five = district_sfs_five.get_metric_dict()\n",
    "\n",
    "# Get the best scores (least negative mean squared error)\n",
    "district_best_score_ten = max(district_cv_scores_ten.values(), key=lambda x: x['avg_score'])\n",
    "district_best_score_five = max(district_cv_scores_five.values(), key=lambda x: x['avg_score'])\n",
    "\n",
    "# Define the final model based on the best score\n",
    "district_selected_features = district_sfs_ten.feature_names_ if district_best_score_ten > district_best_score_five else district_sfs_five.feature_names_\n",
    "lr_district_feature_training_data = lr_district_feature_training_data[list(district_selected_features)]\n",
    "lr_district_feature_testing_data = lr_district_feature_testing_data[list(district_selected_features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the final area model\n",
    "area_final_lr_model = LinearRegression()\n",
    "area_final_lr_model.fit(lr_area_feature_training_data, area_target_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the final district model\n",
    "district_final_lr_model = LinearRegression()\n",
    "district_final_lr_model.fit(lr_district_feature_training_data, district_target_training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the area model\n",
    "area_predictions = area_final_lr_model.predict(lr_area_feature_testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics for the area model\n",
    "area_mse = mean_squared_error(area_target_testing_data, area_predictions)\n",
    "area_rmse = np.sqrt(area_mse)\n",
    "area_mae = mean_absolute_error(area_target_testing_data, area_predictions)\n",
    "area_r2 = r2_score(area_target_testing_data, area_predictions)\n",
    "\n",
    "# Print evaluation metrics for the area model\n",
    "print(\"Area Model Performance Metrics:\")\n",
    "print(f\"Mean Squared Error (MSE): {area_mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {area_rmse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {area_mae}\")\n",
    "print(f\"R^2 Score: {area_r2}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the district model\n",
    "district_predictions = district_final_lr_model.predict(lr_district_feature_testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics for the district model\n",
    "district_mse = mean_squared_error(district_target_testing_data, district_predictions)\n",
    "district_rmse = np.sqrt(district_mse)\n",
    "district_mae = mean_absolute_error(district_target_testing_data, district_predictions)\n",
    "district_r2 = r2_score(district_target_testing_data, district_predictions)\n",
    "\n",
    "# Print evaluation metrics for the district model\n",
    "print(\"District Model Performance Metrics:\")\n",
    "print(f\"Mean Squared Error (MSE): {district_mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {district_rmse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {district_mae}\")\n",
    "print(f\"R^2 Score: {district_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import sort\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_area_feature_training_data = lr_area_feature_training_data.copy()\n",
    "xgb_area_feature_testing_data = lr_area_feature_testing_data.copy()\n",
    "\n",
    "xgb_district_feature_training_data = lr_district_feature_training_data.copy()\n",
    "xgb_district_feature_testing_data = lr_district_feature_testing_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training the Area XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_model = XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1)\n",
    "area_model.fit(xgb_area_feature_training_data, area_target_training_data.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate initial accuracy\n",
    "area_y_pred = area_model.predict(xgb_area_feature_testing_data)\n",
    "area_accuracy = accuracy_score(area_target_testing_data, area_y_pred)\n",
    "\n",
    "print(f\"Accuracy: {area_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_thresholds = sort(area_model.feature_importances_)\n",
    "# Initialize variables to store the best results\n",
    "area_best_accuracy = area_accuracy\n",
    "area_best_thresh = None\n",
    "area_best_features = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over thresholds to find the best feature set\n",
    "for thresh in area_thresholds:\n",
    "    # Select features using the threshold\n",
    "    area_selection = SelectFromModel(area_model, threshold=thresh, prefit=True)\n",
    "    area_select_X_train = area_selection.transform(xgb_area_feature_training_data)\n",
    "\n",
    "    # Train the new model with selected features\n",
    "    area_selection_model = XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1)\n",
    "    area_selection_model.fit(area_select_X_train, area_target_training_data)\n",
    "\n",
    "    # Evaluate the new model\n",
    "    area_select_X_test = area_selection.transform(xgb_area_feature_testing_data)\n",
    "    area_predictions = area_selection_model.predict(area_select_X_test)\n",
    "    area_accuracy = accuracy_score(area_target_testing_data, area_predictions)\n",
    "    \n",
    "    # Print the results for the current threshold\n",
    "    print(f\"Thresh={thresh:.3f}, n={area_select_X_train.shape[1]}, Accuracy: {area_accuracy*100.0:.2f}%\")\n",
    "    \n",
    "    # Update the best accuracy and corresponding features if improved\n",
    "    if area_accuracy > area_best_accuracy:\n",
    "        area_best_accuracy = area_accuracy\n",
    "        area_best_thresh = thresh\n",
    "        area_best_features = area_selection.get_support(indices=True)\n",
    "\n",
    "# Print the best threshold and corresponding accuracy\n",
    "print(f\"Best Thresh={area_best_thresh:.3f}, Best Accuracy: {area_best_accuracy*100.0:.2f}%\")\n",
    "print(f\"Best Features: {area_best_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_area_feature_training_data = xgb_area_feature_training_data.iloc[:, area_best_features]\n",
    "xgb_area_feature_testing_data = xgb_area_feature_testing_data.iloc[:, area_best_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training the District XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_model = XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1)\n",
    "district_model.fit(xgb_district_feature_training_data, district_target_training_data.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_y_pred = district_model.predict(xgb_district_feature_testing_data)\n",
    "district_accuracy = accuracy_score(district_target_testing_data, district_y_pred)\n",
    "print(f\"Accuracy: {district_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine thresholds based on feature importances\n",
    "district_thresholds = np.sort(district_model.feature_importances_)\n",
    "district_best_accuracy = district_accuracy\n",
    "district_best_thresh = None\n",
    "district_best_features = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for thresh in district_thresholds:\n",
    "    # Select features using the threshold\n",
    "    district_selection = SelectFromModel(district_model, threshold=thresh, prefit=True)\n",
    "    district_select_X_train = district_selection.transform(xgb_district_feature_training_data)\n",
    "\n",
    "    # Train the new model with selected features\n",
    "    district_selection_model = XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1)\n",
    "    district_selection_model.fit(district_select_X_train, district_target_training_data)\n",
    "\n",
    "    # Evaluate the new model\n",
    "    district_select_X_test = district_selection.transform(xgb_district_feature_testing_data)\n",
    "    district_predictions = district_selection_model.predict(district_select_X_test)\n",
    "    district_accuracy = accuracy_score(district_target_testing_data, district_predictions)\n",
    "    \n",
    "    # Print the results for the current threshold\n",
    "    print(f\"Thresh={thresh:.3f}, n={district_select_X_train.shape[1]}, Accuracy: {district_accuracy*100.0:.2f}%\")\n",
    "    \n",
    "    # Update the best accuracy and corresponding features if improved\n",
    "    if district_accuracy > district_best_accuracy:\n",
    "        district_best_accuracy = district_accuracy\n",
    "        district_best_thresh = thresh\n",
    "        district_best_features = district_selection.get_support(indices=True)\n",
    "\n",
    "# Print the best threshold and corresponding accuracy\n",
    "print(f\"Best Thresh={district_best_thresh:.3f}, Best Accuracy: {district_best_accuracy*100.0:.2f}%\")\n",
    "print(f\"Best Features: {district_best_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_district_feature_training_data = xgb_district_feature_training_data.iloc[:, district_best_features]\n",
    "xgb_district_feature_testing_data = xgb_district_feature_testing_data.iloc[:, district_best_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'subsample': [0.5, 0.7, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the XGBoost model object\n",
    "area_xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "area_grid_search = GridSearchCV(area_xgb_model, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "area_grid_search.fit(xgb_area_feature_training_data, xgb_area_feature_testing_data.values.ravel())\n",
    "\n",
    "# Print the best set of hyperparameters and the corresponding score\n",
    "print(\"Best set of hyperparameters: \", area_grid_search.best_params_)\n",
    "print(\"Best score: \", area_grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the XGBoost model object\n",
    "district_xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "district_grid_search = GridSearchCV(area_xgb_model, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "district_grid_search.fit(xgb_district_feature_training_data, xgb_district_feature_testing_data.values.ravel())\n",
    "\n",
    "# Print the best set of hyperparameters and the corresponding score\n",
    "print(\"Best set of hyperparameters: \", district_grid_search.best_params_)\n",
    "print(\"Best score: \", district_grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training of Final XGBoost Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the best parameters from the grid search\n",
    "area_best_params = area_grid_search.best_params_\n",
    "\n",
    "# Create the final model with the best parameters\n",
    "area_final_xgb_model = XGBClassifier(**area_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the final model with the selected features from the training data\n",
    "area_final_xgb_model.fit(xgb_area_feature_training_data, area_target_training_data.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the final model on the test data\n",
    "area_final_predictions = area_final_xgb_model.predict(xgb_area_feature_testing_data)\n",
    "area_final_accuracy = accuracy_score(area_target_testing_data, area_final_predictions)\n",
    "print(f\"Final Model Accuracy: {area_final_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the best parameters from the grid search\n",
    "district_best_params = district_grid_search.best_params_\n",
    "\n",
    "# Create the final model with the best parameters\n",
    "district_final_xgb_model = XGBClassifier(**district_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the final model with the selected features from the training data\n",
    "district_final_xgb_model.fit(xgb_district_feature_training_data, district_target_training_data.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the final model on the test data\n",
    "district_final_predictions = district_final_xgb_model.predict(xgb_district_feature_testing_data)\n",
    "district_final_accuracy = accuracy_score(district_target_testing_data, district_final_predictions)\n",
    "print(f\"Final Model Accuracy: {district_final_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_area_feature_training_data = lr_area_feature_training_data.copy()\n",
    "rf_area_feature_testing_data = lr_area_feature_testing_data.copy()\n",
    "\n",
    "rf_district_feature_training_data = lr_district_feature_training_data.copy()\n",
    "rf_district_feature_testing_data = lr_district_feature_testing_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training Initial Area RF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_area_model = RandomForestRegressor(verbose=2)\n",
    "rf_area_model.fit(rf_area_feature_training_data, area_target_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_acc_initial = rf_area_model.score(rf_area_feature_testing_data, area_target_testing_data)\n",
    "print(f'Accuracy before feature selection: {area_acc_initial:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_importances = rf_area_model.feature_importances_\n",
    "area_feature_names = area_feature_training_data.columns\n",
    "\n",
    "area_feature_importance_df = pd.DataFrame({'feature':area_feature_names, 'importance':area_importances})\n",
    "area_feature_importance_df.sort_values(by='importance', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in area_feature_importance_df.iterrows():\n",
    "    print(row['feature'], '- importance:', row['importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_cumulative_importance = np.cumsum(area_feature_importance_df['importance'])\n",
    "area_threshold = 0.95\n",
    "area_selected_features = area_feature_importance_df['feature'][area_cumulative_importance <= area_threshold]\n",
    "\n",
    "rf_area_feature_training_data = rf_area_feature_training_data[area_selected_features]\n",
    "rf_area_feature_testing_data = rf_area_feature_testing_data[area_selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training initial District RF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_district_model = RandomForestRegressor(verbose=2)\n",
    "rf_district_model.fit(rf_district_feature_training_data, district_target_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_acc_initial = rf_district_model.score(rf_district_feature_testing_data, district_target_testing_data)\n",
    "print(f'Accuracy before feature selection: {district_acc_initial:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_importances = rf_district_model.feature_importances_\n",
    "district_feature_names = district_feature_training_data.columns\n",
    "\n",
    "district_feature_importance_df = pd.DataFrame({'feature':district_feature_names, 'importance':district_importances})\n",
    "district_feature_importance_df.sort_values(by='importance', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in district_feature_importance_df.iterrows():\n",
    "    print(row['feature'], '- importance:', row['importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_cumulative_importance = np.cumsum(district_feature_importance_df['importance'])\n",
    "district_threshold = 0.95\n",
    "district_selected_features = district_feature_importance_df['feature'][district_cumulative_importance <= district_threshold]\n",
    "\n",
    "rf_district_feature_training_data = rf_district_feature_training_data[district_selected_features]\n",
    "rf_district_feature_testing_data = rf_district_feature_testing_data[district_selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [10, 20, 30, 40, 50, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_area_model = RandomForestRegressor(random_state=42)\n",
    "grid_search_area = GridSearchCV(estimator=rf_area_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_area.fit(rf_area_feature_training_data, area_target_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_area = grid_search_area.best_params_\n",
    "best_score_area = grid_search_area.best_score_\n",
    "print(f'Best Parameters for Area Model: {best_params_area}')\n",
    "print(f'Best R2 Score for Area Model: {best_score_area:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_district_model = RandomForestRegressor(random_state=42)\n",
    "grid_search_district = GridSearchCV(estimator=rf_district_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_district.fit(rf_district_feature_training_data, district_target_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_district = grid_search_district.best_params_\n",
    "best_score_district = grid_search_district.best_score_\n",
    "print(f'Best Parameters for District Model: {best_params_district}')\n",
    "print(f'Best R2 Score for District Model: {best_score_district:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training the Final RF Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rf_area_model = grid_search_area.best_estimator_\n",
    "final_rf_area_model.fit(rf_area_feature_training_data, area_target_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_acc_final = final_rf_area_model.score(rf_area_feature_testing_data, area_target_testing_data)\n",
    "print(f'Final Accuracy for Area Model after Hyperparameter Tuning: {area_acc_final:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rf_district_model = grid_search_district.best_estimator_\n",
    "final_rf_district_model.fit(rf_district_feature_training_data, district_target_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_acc_final = final_rf_district_model.score(rf_district_feature_testing_data, district_target_testing_data)\n",
    "print(f'Final Accuracy for District Model after Hyperparameter Tuning: {district_acc_final:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
